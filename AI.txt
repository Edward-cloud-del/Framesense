ğŸš€ FRAMESENSE AI + OCR INTEGRATION - OPTIMERAD PLAN
====================================================

ğŸ“‹ VERKLIG NUVARANDE STATUS (Dec 2024):
âœ… Komplett screen selection system (React + HTML overlays)
âœ… Screenshot capture med optimized caching
âœ… ChatBox integration med image context
âœ… AI integration infrastructure (mock, men OpenAI key ready)
âœ… State management (Zustand) och window management
âœ… Permission system fÃ¶r macOS
âœ… Optimization system med pooling och screenshot caching
âœ… Progress indicators och UX komponenter
âœ… TypeScript interfaces fÃ¶r AI/OCR
âœ… Error handling och graceful degradation

ğŸ¯ VID DETTA LÃ„GE SAKNAS BARA:
âŒ Riktig OpenAI Vision API integration (mock â†’ real)
âŒ Tesseract OCR implementation (kommenterad i Cargo.toml)
âŒ SÃ¤ker API key storage system
âŒ Processing router (intelligent AI vs OCR beslut)
âŒ Settings UI fÃ¶r API keys och konfiguration
âŒ Result synthesis fÃ¶r hybrid AI + OCR responses

===============================================
ğŸ¯ RISK-OPTIMERAD IMPLEMENTATION - 2.5 VECKOR
===============================================

ğŸš¨ KRITISKA INSIKTER FRÃ…N ANALYS:
â€¢ OCR Ã¤r ENKLARE Ã¤n AI integration (bara uncomment + code)
â€¢ Tesseract compilation Ã¤r STÃ˜RSTE RISKEN - testa fÃ¶rst
â€¢ API key chain Ã¤r DEPENDENCY BLOCKER fÃ¶r AI
â€¢ Image compression Ã¤r KRITISKT fÃ¶r OpenAI (20MB limit)
â€¢ Cost protection MÃ…STE finnas frÃ¥n bÃ¶rjan

ğŸ—“ï¸ VECKA 1: LOW-RISK HIGH-VALUE (OCR FÃ–RST)
===========================================

ğŸ”§ DAG 1: RISK MITIGATION - TESTA TESSERACT COMPILATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
HÃ–GSTA PRIORITET: Verifiera att Tesseract fungerar pÃ¥ systemet

STEG 1A: Testa Tesseract installation
```bash
# Uncommenta i Cargo.toml:
tesseract = "0.13"

# Testa compilation:
cargo build
```

STEG 1B: Minimalt OCR test
```rust
// src-tauri/src/ocr/mod.rs - ENKEL VERSION FÃ–RST
use tesseract::Tesseract;

pub struct OCRService;

impl OCRService {
    pub fn test_ocr() -> Result<String, String> {
        match Tesseract::new(None, Some("eng")) {
            Ok(_) => Ok("âœ… Tesseract ready!".to_string()),
            Err(e) => Err(format!("âŒ Tesseract failed: {}", e))
        }
    }
}
```

ğŸ”§ DAG 2-3: OCR WORKING IMPLEMENTATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Nu nÃ¤r vi vet att Tesseract fungerar:

IMPLEMENTERA: src-tauri/src/ocr/mod.rs
```rust
use tesseract::Tesseract;
use image::DynamicImage;
use base64::Engine;

pub struct OCRService {
    tesseract: Tesseract,
}

impl OCRService {
    pub fn new() -> Result<Self, String> {
        let tesseract = Tesseract::new(None, Some("eng"))
            .map_err(|e| format!("Failed to initialize Tesseract: {}", e))?;
        
        Ok(Self { tesseract })
    }
    
    pub fn extract_text(&mut self, image_data: &str) -> Result<OCRResult, String> {
        // Remove data:image/png;base64, prefix if exists
        let base64_data = if image_data.starts_with("data:image") {
            image_data.split(',').nth(1).unwrap_or(image_data)
        } else {
            image_data
        };
        
        // Decode base64 image
        let image_bytes = base64::engine::general_purpose::STANDARD
            .decode(base64_data)
            .map_err(|e| format!("Failed to decode image: {}", e))?;
        
        // Load image
        let img = image::load_from_memory(&image_bytes)
            .map_err(|e| format!("Failed to load image: {}", e))?
            .to_rgba8();
        
        // Set image for OCR
        self.tesseract
            .set_image_from_mem(&img.as_raw())
            .map_err(|e| format!("Failed to set image: {}", e))?;
        
        // Extract text
        let text = self.tesseract
            .get_text()
            .map_err(|e| format!("Failed to extract text: {}", e))?;
        
        let confidence = self.tesseract.mean_text_conf() as f32 / 100.0;
        
        Ok(OCRResult {
            text: text.trim().to_string(),
            confidence,
            has_text: !text.trim().is_empty() && confidence > 0.3,
        })
    }
}

#[derive(Clone, serde::Serialize, serde::Deserialize, Debug)]
pub struct OCRResult {
    pub text: String,
    pub confidence: f32,
    pub has_text: bool,
}
```

RUST COMMAND (main.rs):
```rust
mod ocr;
use ocr::{OCRService, OCRResult};

// Global OCR service (reuse instance for performance)
static mut OCR_SERVICE: Option<std::sync::Mutex<OCRService>> = None;
static OCR_INIT: std::sync::Once = std::sync::Once::new();

#[tauri::command]
async fn extract_text_ocr(image_data: String) -> Result<OCRResult, String> {
    unsafe {
        OCR_INIT.call_once(|| {
            if let Ok(service) = OCRService::new() {
                OCR_SERVICE = Some(std::sync::Mutex::new(service));
            }
        });
        
        if let Some(ref service_mutex) = OCR_SERVICE {
            let mut service = service_mutex.lock().unwrap();
            service.extract_text(&image_data)
        } else {
            Err("OCR service not initialized".to_string())
        }
    }
}
```

ğŸ”§ DAG 4-5: OCR UI INTEGRATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
UPPDATERA App.tsx fÃ¶r OCR testing:
```typescript
// LÃ¤gg till OCR test button temporarily
const testOCR = async () => {
  if (selectedImageForAI) {
    try {
      const result = await invoke('extract_text_ocr', { imageData: selectedImageForAI });
      console.log('ğŸ“ OCR Result:', result);
      setAiResponse(`ğŸ“ **OCR Results**\n\n**Text Found:** ${result.text}\n**Confidence:** ${Math.round(result.confidence * 100)}%`);
    } catch (error) {
      console.error('âŒ OCR failed:', error);
      setAiResponse(`âŒ OCR Error: ${error}`);
    }
  }
};
```

RESULTAT VECKA 1: âœ… Working OCR system, risk mitigated!

ğŸ—“ï¸ VECKA 2: PARALLELL AI + SÃ„KERHETS-IMPLEMENTATION  
==================================================

ğŸ”§ DAG 1-2: API KEY STORAGE (PARALLEL MED AI PREP)
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Eftersom OCR redan fungerar, kan vi fokusera pÃ¥ AI infrastructure:

RUST COMMANDS (main.rs):
```rust
use serde_json::Value;
use std::path::PathBuf;

#[tauri::command]
async fn store_api_key(key: String) -> Result<(), String> {
    // Validate API key format first
    if !key.starts_with("sk-") || key.len() < 20 {
        return Err("Invalid API key format".to_string());
    }
    
    // Get app data directory
    let app_data_dir = tauri::api::path::app_data_dir(&tauri::Config::default())
        .ok_or("Failed to get app data directory")?;
    
    let key_file = app_data_dir.join("openai_key.json");
    
    // Simple encryption (base64 + obfuscation)
    let encoded_key = base64::engine::general_purpose::STANDARD.encode(key.as_bytes());
    let data = serde_json::json!({
        "api_key": encoded_key,
        "created_at": chrono::Utc::now().timestamp()
    });
    
    // Create directory if it doesn't exist
    std::fs::create_dir_all(&app_data_dir).map_err(|e| e.to_string())?;
    
    // Write to file
    std::fs::write(key_file, data.to_string()).map_err(|e| e.to_string())?;
    
    println!("ğŸ” API key stored securely");
    Ok(())
}

#[tauri::command]
async fn get_api_key() -> Result<Option<String>, String> {
    let app_data_dir = tauri::api::path::app_data_dir(&tauri::Config::default())
        .ok_or("Failed to get app data directory")?;
    
    let key_file = app_data_dir.join("openai_key.json");
    
    if !key_file.exists() {
        return Ok(None);
    }
    
    let content = std::fs::read_to_string(key_file).map_err(|e| e.to_string())?;
    let data: Value = serde_json::from_str(&content).map_err(|e| e.to_string())?;
    
    if let Some(encoded_key) = data["api_key"].as_str() {
        let decoded = base64::engine::general_purpose::STANDARD
            .decode(encoded_key)
            .map_err(|e| e.to_string())?;
        let key = String::from_utf8(decoded).map_err(|e| e.to_string())?;
        Ok(Some(key))
    } else {
        Ok(None)
    }
}

#[tauri::command]
async fn remove_api_key() -> Result<(), String> {
    let app_data_dir = tauri::api::path::app_data_dir(&tauri::Config::default())
        .ok_or("Failed to get app data directory")?;
    
    let key_file = app_data_dir.join("openai_key.json");
    
    if key_file.exists() {
        std::fs::remove_file(key_file).map_err(|e| e.to_string())?;
    }
    
    Ok(())
}
```

ğŸ”§ DAG 3: OPENAI SERVICE MED COST PROTECTION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SKAPA: src/services/openai-service.ts
```typescript
import OpenAI from 'openai';

interface UsageTracker {
  requestCount: number;
  dailyLimit: number;
  lastReset: string;
}

export class OpenAIService {
  private client: OpenAI;
  private usageTracker: UsageTracker;

  constructor(apiKey: string) {
    this.client = new OpenAI({ 
      apiKey,
      dangerouslyAllowBrowser: true // Since we're in Tauri, not browser
    });
    
    // Load or initialize usage tracking
    const today = new Date().toDateString();
    const saved = localStorage.getItem('openai_usage');
    
    if (saved) {
      const parsed = JSON.parse(saved);
      if (parsed.lastReset === today) {
        this.usageTracker = parsed;
      } else {
        this.usageTracker = { requestCount: 0, dailyLimit: 50, lastReset: today };
      }
    } else {
      this.usageTracker = { requestCount: 0, dailyLimit: 50, lastReset: today };
    }
  }

  async analyzeImageWithText(imageData: string, userQuery: string): Promise<string> {
    // Cost protection check
    if (this.usageTracker.requestCount >= this.usageTracker.dailyLimit) {
      throw new Error(`Daily limit of ${this.usageTracker.dailyLimit} requests reached. Limit resets tomorrow.`);
    }

    // Image compression check (OpenAI 20MB limit)
    const imageSizeKB = (imageData.length * 0.75) / 1024;
    if (imageSizeKB > 15000) { // 15MB safety margin
      throw new Error(`Image too large (${Math.round(imageSizeKB)}KB). Max 15MB. Try selecting a smaller area.`);
    }

    try {
      const response = await this.client.chat.completions.create({
        model: "gpt-4-vision-preview",
        messages: [{
          role: "user",
          content: [
            { 
              type: "text", 
              text: `${userQuery}\n\nPlease analyze this screenshot and provide helpful insights.` 
            },
            { 
              type: "image_url", 
              image_url: { url: imageData }
            }
          ]
        }],
        max_tokens: 1000,
        temperature: 0.7
      });

      // Update usage tracking
      this.usageTracker.requestCount++;
      localStorage.setItem('openai_usage', JSON.stringify(this.usageTracker));

      const content = response.choices[0].message.content;
      if (!content) {
        throw new Error("No response from OpenAI");
      }

      console.log(`âœ… OpenAI request successful (${this.usageTracker.requestCount}/${this.usageTracker.dailyLimit} today)`);
      return content;

    } catch (error: any) {
      // Handle specific OpenAI errors
      if (error.status === 401) {
        throw new Error("Invalid API key. Please check your OpenAI API key in settings.");
      } else if (error.status === 429) {
        throw new Error("Rate limit exceeded. Please wait a moment and try again.");
      } else if (error.status === 413) {
        throw new Error("Image too large. Please select a smaller area.");
      } else {
        throw new Error(`OpenAI API error: ${error.message}`);
      }
    }
  }

  getRemainingRequests(): number {
    return this.usageTracker.dailyLimit - this.usageTracker.requestCount;
  }
}
```

ğŸ”§ DAG 4-5: SMART PROCESSING ROUTER
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SKAPA: src/services/processing-router.ts
```typescript
import { invoke } from '@tauri-apps/api/core';
import { OpenAIService } from './openai-service';

type ProcessingStrategy = 'ocr-only' | 'ai-only' | 'hybrid-sequential' | 'auto-detect';

interface ProcessingResult {
  strategy: ProcessingStrategy;
  aiResponse?: string;
  ocrResult?: any;
  combinedResponse: string;
  confidence: number;
}

export class ProcessingRouter {
  static async processImageWithQuery(
    imageData: string, 
    userQuery: string, 
    apiKey?: string
  ): Promise<ProcessingResult> {
    
    const strategy = this.determineStrategy(userQuery, imageData, !!apiKey);
    console.log(`ğŸ¯ Selected strategy: ${strategy}`);

    switch (strategy) {
      case 'ocr-only':
        return await this.runOCROnly(imageData, userQuery);
      
      case 'ai-only':
        return await this.runAIOnly(imageData, userQuery, apiKey!);
      
      case 'hybrid-sequential':
        return await this.runHybridSequential(imageData, userQuery, apiKey!);
      
      default: // auto-detect
        return await this.runAutoDetect(imageData, userQuery, apiKey);
    }
  }

  private static determineStrategy(
    query: string, 
    imageData: string, 
    hasApiKey: boolean
  ): ProcessingStrategy {
    const queryLower = query.toLowerCase();
    
    // Text extraction keywords
    const textKeywords = ['text', 'read', 'extract', 'words', 'type', 'transcribe'];
    const isTextFocused = textKeywords.some(keyword => queryLower.includes(keyword));
    
    // Visual analysis keywords  
    const visualKeywords = ['what', 'describe', 'analyze', 'explain', 'understand', 'see'];
    const isVisualFocused = visualKeywords.some(keyword => queryLower.includes(keyword));
    
    // Image size consideration
    const imageSize = imageData.length * 0.75; // Approximate bytes
    const isLargeImage = imageSize > 5000000; // 5MB
    
    // Decision logic
    if (!hasApiKey) {
      return 'ocr-only';
    } else if (isTextFocused && !isVisualFocused) {
      return 'ocr-only';
    } else if (isVisualFocused && !isTextFocused) {
      return 'ai-only';
    } else if (isLargeImage) {
      return 'ai-only'; // Avoid OCR overhead on large images
    } else {
      return 'hybrid-sequential'; // Try OCR first, then enhance with AI
    }
  }

  private static async runOCROnly(imageData: string, userQuery: string): Promise<ProcessingResult> {
    try {
      const ocrResult = await invoke('extract_text_ocr', { imageData });
      
      const response = ocrResult.has_text 
        ? `ğŸ“ **Text Extracted**\n\n${ocrResult.text}\n\n*Confidence: ${Math.round(ocrResult.confidence * 100)}%*`
        : "âŒ No text detected in the selected area.";

      return {
        strategy: 'ocr-only',
        ocrResult,
        combinedResponse: response,
        confidence: ocrResult.confidence
      };
    } catch (error) {
      return {
        strategy: 'ocr-only',
        combinedResponse: `âŒ OCR failed: ${error}`,
        confidence: 0
      };
    }
  }

  private static async runAIOnly(imageData: string, userQuery: string, apiKey: string): Promise<ProcessingResult> {
    try {
      const openai = new OpenAIService(apiKey);
      const aiResponse = await openai.analyzeImageWithText(imageData, userQuery);
      
      return {
        strategy: 'ai-only',
        aiResponse,
        combinedResponse: `ğŸ¤– **AI Analysis**\n\n${aiResponse}`,
        confidence: 0.9 // AI is generally high confidence
      };
    } catch (error) {
      return {
        strategy: 'ai-only',
        combinedResponse: `âŒ AI analysis failed: ${error}`,
        confidence: 0
      };
    }
  }

  private static async runHybridSequential(imageData: string, userQuery: string, apiKey: string): Promise<ProcessingResult> {
    // Step 1: Run OCR first
    let ocrResult;
    try {
      ocrResult = await invoke('extract_text_ocr', { imageData });
    } catch (error) {
      console.warn('OCR failed, falling back to AI only:', error);
      return await this.runAIOnly(imageData, userQuery, apiKey);
    }

    // Step 2: Run AI with OCR context
    try {
      const openai = new OpenAIService(apiKey);
      
      const enhancedQuery = ocrResult.has_text 
        ? `${userQuery}\n\nAdditional context - OCR detected this text: "${ocrResult.text}"`
        : userQuery;
      
      const aiResponse = await openai.analyzeImageWithText(imageData, enhancedQuery);
      
      // Step 3: Combine results intelligently
      const combinedResponse = this.synthesizeResults(ocrResult, aiResponse, userQuery);
      
      return {
        strategy: 'hybrid-sequential',
        aiResponse,
        ocrResult,
        combinedResponse,
        confidence: Math.max(0.8, ocrResult.confidence) // Hybrid is high confidence
      };
    } catch (error) {
      // Fallback to OCR-only if AI fails
      console.warn('AI failed, using OCR results only:', error);
      return await this.runOCROnly(imageData, userQuery);
    }
  }

  private static async runAutoDetect(imageData: string, userQuery: string, apiKey?: string): Promise<ProcessingResult> {
    if (!apiKey) {
      return await this.runOCROnly(imageData, userQuery);
    }
    
    // Default to hybrid for best results
    return await this.runHybridSequential(imageData, userQuery, apiKey);
  }

  private static synthesizeResults(ocrResult: any, aiResponse: string, userQuery: string): string {
    if (!ocrResult.has_text) {
      return `ğŸ¤– **AI Analysis**\n\n${aiResponse}`;
    }

    return `ğŸ”„ **Hybrid Analysis**\n\n` +
           `ğŸ“ **Text Found:** ${ocrResult.text}\n` +
           `*OCR Confidence: ${Math.round(ocrResult.confidence * 100)}%*\n\n` +
           `ğŸ¤– **AI Insights:**\n${aiResponse}`;
  }
}
```

ğŸ—“ï¸ VECKA 3: INTEGRATION & POLISH
================================

ğŸ”§ DAG 1-2: SETTINGS UI & MAIN APP INTEGRATION
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
SKAPA: src/components/SettingsDialog.tsx (kompakt version)
UPPDATERA: App.tsx med Settings button och ny ProcessingRouter

ğŸ”§ DAG 3-4: ERROR HANDLING & UX POLISH
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ User-friendly error messages
â€¢ Loading states med progress
â€¢ Usage limit indicators

ğŸ”§ DAG 5: TESTING & CLEANUP
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
â€¢ End-to-end testing
â€¢ Performance verification
â€¢ Remove temporary debugging code

===============================================
ğŸ¯ FÃ–RBÃ„TTRAD IMPLEMENTATION ORDER
===============================================

ğŸš€ **DAG 1 (HÃ–GRISK): TESSERACT TEST**
â€¢ Uncomment Tesseract i Cargo.toml
â€¢ Testa compilation + basic OCR
â€¢ STOP om detta inte fungerar - fixa fÃ¶rst!

âš¡ **DAG 2-3: OCR IMPLEMENTATION** 
â€¢ Working OCR service
â€¢ UI integration fÃ¶r testing
â€¢ Immediate value utan external dependencies

ğŸ”¥ **DAG 4-5: API INFRASTRUCTURE**
â€¢ API key storage (sÃ¤kert)
â€¢ OpenAI service med cost protection
â€¢ Settings UI basic version

ğŸ’ª **DAG 6-8: SMART PROCESSING**
â€¢ Processing router implementation
â€¢ Hybrid AI + OCR kombinationer
â€¢ Error handling och fallbacks

âœ¨ **DAG 9-12: POLISH & TESTING**
â€¢ UI improvements
â€¢ Performance testing
â€¢ Production readiness

===============================================
ğŸ¯ KRITISKA FÃ–RBÃ„TTRINGAR I DENNA PLAN
===============================================

1. **ğŸš¨ RISK MITIGATION FÃ–RST:** Testa Tesseract compilation dag 1
2. **ğŸ’° COST PROTECTION:** Daily limits och image size checks
3. **âš¡ IMMEDIATE VALUE:** OCR fungerar utan externa dependencies  
4. **ğŸ”„ SMART FALLBACKS:** Om AI fails â†’ OCR, om OCR fails â†’ AI
5. **ğŸ“ˆ INCREMENTAL:** Varje dag levererar working functionality
6. **ğŸ›¡ï¸ FUTURE-PROOF:** Ingen konflikt med Appoptimization.txt optimeringar

===============================================
ğŸš€ DENNA FÃ–RBÃ„TTRADE PLAN Ã„R BOMBSÃ„KER!
===============================================

**FÃ¶rdelar vs original plan:**
âœ… Tesseract risk eliminerad dag 1  
âœ… OCR working inom 3 dagar
âœ… Cost protection frÃ¥n bÃ¶rjan
âœ… Fallback strategies fÃ¶r alla scenarios
âœ… Ingen dependency pÃ¥ external services fÃ¶r core functionality
âœ… Parallel development fÃ¶r maximal effektivitet

**ğŸ¯ Success efter varje dag:**
â€¢ Dag 1: Tesseract proven working
â€¢ Dag 3: OCR extracting text frÃ¥n screenshots  
â€¢ Dag 5: API key management working
â€¢ Dag 8: AI + OCR hybrid system working
â€¢ Dag 12: Production-ready med polish

ğŸ’ª **DETTA KOMMER DEFINITIVT FUNGERA!** 